{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 아둔토리다스 팀\n",
    "## ai factory spark 챌린지 참여 코드\n",
    "### predict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "haversine 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install haversine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package Version 명시"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package                       Version\n",
    "----------------------------- ---------\n",
    "absl-py                       1.4.0\n",
    "aiohttp                       3.8.1\n",
    "aiosignal                     1.2.0\n",
    "alabaster                     0.7.12\n",
    "alembic                       1.10.3\n",
    "anaconda-client               1.9.0\n",
    "anaconda-project              0.10.2\n",
    "ansi2html                     1.8.0\n",
    "anyio                         3.5.0\n",
    "appdirs                       1.4.4\n",
    "argon2-cffi                   21.3.0\n",
    "argon2-cffi-bindings          21.2.0\n",
    "arrow                         1.2.2\n",
    "astroid                       2.6.6\n",
    "astropy                       5.0.4\n",
    "asttokens                     2.0.5\n",
    "astunparse                    1.6.3\n",
    "async-generator               1.10\n",
    "async-timeout                 4.0.1\n",
    "atomicwrites                  1.4.0\n",
    "attrs                         21.4.0\n",
    "Automat                       20.2.0\n",
    "autopep8                      1.6.0\n",
    "Babel                         2.9.1\n",
    "backcall                      0.2.0\n",
    "backports.functools-lru-cache 1.6.4\n",
    "backports.tempfile            1.0\n",
    "backports.weakref             1.0.post1\n",
    "bayesian-optimization         1.4.3\n",
    "bcrypt                        3.2.0\n",
    "beautifulsoup4                4.11.1\n",
    "binaryornot                   0.4.4\n",
    "bitarray                      2.4.1\n",
    "bkcharts                      0.2\n",
    "black                         19.10b0\n",
    "bleach                        4.1.0\n",
    "blinker                       1.6.2\n",
    "bokeh                         2.4.2\n",
    "boltons                       23.0.0\n",
    "boto3                         1.21.32\n",
    "botocore                      1.24.32\n",
    "Bottleneck                    1.3.4\n",
    "brotlipy                      0.7.0\n",
    "cachetools                    4.2.2\n",
    "catboost                      1.1.1\n",
    "category-encoders             2.6.0\n",
    "certifi                       2023.5.7\n",
    "cffi                          1.15.0\n",
    "chardet                       4.0.0\n",
    "charset-normalizer            2.0.4\n",
    "click                         8.1.3\n",
    "cloudpickle                   2.0.0\n",
    "clyent                        1.2.2\n",
    "cmaes                         0.9.1\n",
    "cmdstanpy                     1.1.0\n",
    "colorama                      0.4.6\n",
    "colorcet                      2.0.6\n",
    "colorlog                      6.7.0\n",
    "comtypes                      1.1.10\n",
    "conda                         23.3.1\n",
    "conda-content-trust           0+unknown\n",
    "conda-pack                    0.6.0\n",
    "conda-package-handling        2.0.2\n",
    "conda_package_streaming       0.7.0\n",
    "conda-token                   0.3.0\n",
    "constantly                    15.1.0\n",
    "convertdate                   2.4.0\n",
    "cookiecutter                  1.7.3\n",
    "cramjam                       2.6.2\n",
    "cryptography                  3.4.8\n",
    "cssselect                     1.1.0\n",
    "cycler                        0.11.0\n",
    "Cython                        0.29.28\n",
    "cytoolz                       0.11.0\n",
    "daal4py                       2021.5.0\n",
    "dash                          2.9.3\n",
    "dash-core-components          2.0.0\n",
    "dash-html-components          2.0.0\n",
    "dash-table                    5.0.0\n",
    "dask                          2023.4.1\n",
    "datashader                    0.13.0\n",
    "datashape                     0.5.4\n",
    "debugpy                       1.5.1\n",
    "decorator                     5.1.1\n",
    "defusedxml                    0.7.1\n",
    "Deprecated                    1.2.13\n",
    "deprecation                   2.1.0\n",
    "diff-match-patch              20200713\n",
    "dill                          0.3.6\n",
    "distlib                       0.3.6\n",
    "distributed                   2022.2.1\n",
    "docutils                      0.17.1\n",
    "entrypoints                   0.4\n",
    "ephem                         4.1.4\n",
    "et-xmlfile                    1.1.0\n",
    "exceptiongroup                1.1.1\n",
    "executing                     0.8.3\n",
    "fastjsonschema                2.15.1\n",
    "fastparquet                   2023.4.0\n",
    "filelock                      3.6.0\n",
    "flake8                        3.9.2\n",
    "Flask                         2.3.1\n",
    "flatbuffers                   2.0.7\n",
    "fonttools                     4.25.0\n",
    "frozenlist                    1.2.0\n",
    "fs                            2.4.16\n",
    "fsspec                        2022.2.0\n",
    "future                        0.18.2\n",
    "gast                          0.4.0\n",
    "gensim                        4.1.2\n",
    "glob2                         0.7\n",
    "google-api-core               1.25.1\n",
    "google-auth                   2.17.3\n",
    "google-auth-oauthlib          1.0.0\n",
    "google-cloud-core             1.7.1\n",
    "google-cloud-storage          1.31.0\n",
    "google-crc32c                 1.1.2\n",
    "google-pasta                  0.2.0\n",
    "google-resumable-media        1.3.1\n",
    "googleapis-common-protos      1.53.0\n",
    "graphviz                      0.20.1\n",
    "greenlet                      1.1.1\n",
    "grpcio                        1.54.0\n",
    "h11                           0.14.0\n",
    "h2o                           3.40.0.4\n",
    "h5py                          3.6.0\n",
    "haversine                     2.8.0\n",
    "HeapDict                      1.0.1\n",
    "hijri-converter               2.3.1\n",
    "holidays                      0.23\n",
    "holoviews                     1.14.8\n",
    "huggingface-hub               0.14.1\n",
    "hvplot                        0.7.3\n",
    "hyperlink                     21.0.0\n",
    "hyperopt                      0.2.7\n",
    "idna                          3.3\n",
    "imagecodecs                   2021.8.26\n",
    "imageio                       2.9.0\n",
    "imagesize                     1.3.0\n",
    "imbalanced-learn              0.10.1\n",
    "imblearn                      0.0\n",
    "importlib-metadata            5.2.0\n",
    "impyute                       0.0.8\n",
    "incremental                   21.3.0\n",
    "inflection                    0.5.1\n",
    "iniconfig                     1.1.1\n",
    "intake                        0.6.5\n",
    "intervaltree                  3.1.0\n",
    "ipykernel                     6.9.1\n",
    "ipynb-py-convert              0.4.6\n",
    "ipython                       7.34.0\n",
    "ipython-genutils              0.2.0\n",
    "ipywidgets                    7.6.5\n",
    "isort                         5.9.3\n",
    "itemadapter                   0.3.0\n",
    "itemloaders                   1.0.4\n",
    "itsdangerous                  2.1.2\n",
    "jdcal                         1.4.1\n",
    "jedi                          0.18.1\n",
    "Jinja2                        3.1.2\n",
    "jinja2-time                   0.2.0\n",
    "jmespath                      0.10.0\n",
    "joblib                        1.2.0\n",
    "json5                         0.9.6\n",
    "jsonpatch                     1.32\n",
    "jsonpointer                   2.1\n",
    "jsonschema                    4.4.0\n",
    "jupyter                       1.0.0\n",
    "jupyter-client                6.1.12\n",
    "jupyter-console               6.4.0\n",
    "jupyter-core                  4.9.2\n",
    "jupyter-dash                  0.4.2\n",
    "jupyter-server                1.13.5\n",
    "jupyterlab                    3.3.2\n",
    "jupyterlab-pygments           0.1.2\n",
    "jupyterlab-server             2.10.3\n",
    "jupyterlab-widgets            1.0.0\n",
    "kaleido                       0.2.1\n",
    "keras                         2.7.0\n",
    "Keras-Preprocessing           1.1.2\n",
    "keyring                       23.4.0\n",
    "kiwisolver                    1.3.2\n",
    "korean-lunar-calendar         0.3.1\n",
    "lazy_loader                   0.2\n",
    "lazy-object-proxy             1.6.0\n",
    "libarchive-c                  2.9\n",
    "libclang                      16.0.0\n",
    "lightgbm                      3.3.5\n",
    "llvmlite                      0.38.0\n",
    "locket                        1.0.0\n",
    "LunarCalendar                 0.0.9\n",
    "lxml                          4.8.0\n",
    "Mako                          1.2.4\n",
    "Markdown                      3.3.4\n",
    "MarkupSafe                    2.1.2\n",
    "matplotlib                    3.5.1\n",
    "matplotlib-inline             0.1.2\n",
    "mccabe                        0.6.1\n",
    "menuinst                      1.4.18\n",
    "mistune                       0.8.4\n",
    "mkl-fft                       1.3.1\n",
    "mkl-random                    1.2.2\n",
    "mkl-service                   2.4.0\n",
    "mock                          4.0.3\n",
    "mpmath                        1.2.1\n",
    "msgpack                       1.0.2\n",
    "multidict                     5.1.0\n",
    "multimethod                   1.9.1\n",
    "multipledispatch              0.6.0\n",
    "munkres                       1.1.4\n",
    "mypy-extensions               0.4.3\n",
    "nbclassic                     0.3.5\n",
    "nbclient                      0.5.13\n",
    "nbconvert                     6.4.4\n",
    "nbformat                      5.3.0\n",
    "nest-asyncio                  1.5.5\n",
    "networkx                      3.1\n",
    "nltk                          3.7\n",
    "nose                          1.3.7\n",
    "notebook                      6.4.8\n",
    "numba                         0.55.1\n",
    "numexpr                       2.8.1\n",
    "numpy                         1.21.6\n",
    "numpydoc                      1.2\n",
    "oauthlib                      3.2.2\n",
    "olefile                       0.46\n",
    "openpyxl                      3.0.9\n",
    "opt-einsum                    3.3.0\n",
    "optuna                        3.1.1\n",
    "orjson                        3.8.11\n",
    "outcome                       1.2.0\n",
    "packaging                     21.3\n",
    "pandas                        1.5.3\n",
    "pandocfilters                 1.5.0\n",
    "panel                         0.13.0\n",
    "param                         1.12.0\n",
    "paramiko                      2.8.1\n",
    "parsel                        1.6.0\n",
    "parso                         0.8.3\n",
    "partd                         1.2.0\n",
    "pathspec                      0.7.0\n",
    "patsy                         0.5.2\n",
    "pep8                          1.7.1\n",
    "pexpect                       4.8.0\n",
    "pickleshare                   0.7.5\n",
    "Pillow                        9.0.1\n",
    "pip                           21.2.4\n",
    "pkginfo                       1.8.2\n",
    "platformdirs                  3.5.0\n",
    "plotly                        5.14.1\n",
    "plotly-resampler              0.8.3.2\n",
    "pluggy                        1.0.0\n",
    "pmdarima                      2.0.3\n",
    "poyo                          0.5.0\n",
    "prometheus-client             0.13.1\n",
    "prompt-toolkit                3.0.20\n",
    "prophet                       1.1.2\n",
    "Protego                       0.1.16\n",
    "protobuf                      3.19.6\n",
    "psutil                        5.9.5\n",
    "ptyprocess                    0.7.0\n",
    "pure-eval                     0.2.2\n",
    "py                            1.11.0\n",
    "py4j                          0.10.9.7\n",
    "pyaml                         21.10.1\n",
    "pyarrow                       11.0.0\n",
    "pyasn1                        0.4.8\n",
    "pyasn1-modules                0.2.8\n",
    "pycaret                       3.0.0\n",
    "pycodestyle                   2.7.0\n",
    "pycosat                       0.6.3\n",
    "pycparser                     2.21\n",
    "pyct                          0.4.6\n",
    "pycurl                        7.44.1\n",
    "PyDispatcher                  2.0.5\n",
    "pydocstyle                    6.1.1\n",
    "pyerfa                        2.0.0\n",
    "pyflakes                      2.3.1\n",
    "Pygments                      2.11.2\n",
    "PyHamcrest                    2.0.2\n",
    "pylint                        2.9.6\n",
    "pyls-spyder                   0.4.0\n",
    "PyMeeus                       0.5.12\n",
    "PyNaCl                        1.4.0\n",
    "pyod                          1.0.9\n",
    "pyodbc                        4.0.32\n",
    "pyOpenSSL                     21.0.0\n",
    "pyparsing                     3.0.4\n",
    "pyreadline                    2.1\n",
    "pyrsistent                    0.18.0\n",
    "PySocks                       1.7.1\n",
    "pytest                        7.1.1\n",
    "python-dateutil               2.8.2\n",
    "python-lsp-black              1.0.0\n",
    "python-lsp-jsonrpc            1.0.0\n",
    "python-lsp-server             1.2.4\n",
    "python-slugify                5.0.2\n",
    "python-snappy                 0.6.0\n",
    "pytz                          2021.3\n",
    "pyviz-comms                   2.0.2\n",
    "PyWavelets                    1.3.0\n",
    "pywin32                       306\n",
    "pywin32-ctypes                0.2.0\n",
    "pywinpty                      2.0.2\n",
    "PyYAML                        6.0\n",
    "pyzmq                         22.3.0\n",
    "QDarkStyle                    3.0.2\n",
    "qstylizer                     0.1.10\n",
    "QtAwesome                     1.0.3\n",
    "qtconsole                     5.3.0\n",
    "QtPy                          2.0.1\n",
    "queuelib                      1.5.0\n",
    "regex                         2022.3.15\n",
    "requests                      2.27.1\n",
    "requests-file                 1.5.1\n",
    "requests-oauthlib             1.3.1\n",
    "retrying                      1.3.4\n",
    "rope                          0.22.0\n",
    "rsa                           4.7.2\n",
    "Rtree                         0.9.7\n",
    "ruamel.yaml                   0.17.21\n",
    "ruamel.yaml.clib              0.2.6\n",
    "ruamel-yaml-conda             0.15.100\n",
    "s3transfer                    0.5.0\n",
    "schemdraw                     0.16\n",
    "scikit-learn                  1.2.2\n",
    "scikit-plot                   0.3.7\n",
    "scikit-surprise               1.1.3\n",
    "scipy                         1.9.1\n",
    "Scrapy                        2.6.1\n",
    "seaborn                       0.11.2\n",
    "Send2Trash                    1.8.0\n",
    "service-identity              18.1.0\n",
    "setuptools                    61.2.0\n",
    "setuptools-git                1.2\n",
    "sip                           4.19.13\n",
    "six                           1.16.0\n",
    "sktime                        0.17.2\n",
    "smart-open                    5.1.0\n",
    "sniffio                       1.2.0\n",
    "snowballstemmer               2.2.0\n",
    "sortedcollections             2.1.0\n",
    "sortedcontainers              2.4.0\n",
    "soupsieve                     2.3.1\n",
    "Sphinx                        4.4.0\n",
    "sphinxcontrib-applehelp       1.0.2\n",
    "sphinxcontrib-devhelp         1.0.2\n",
    "sphinxcontrib-htmlhelp        2.0.0\n",
    "sphinxcontrib-jsmath          1.0.1\n",
    "sphinxcontrib-qthelp          1.0.3\n",
    "sphinxcontrib-serializinghtml 1.1.5\n",
    "spyder                        5.1.5\n",
    "spyder-kernels                2.1.3\n",
    "SQLAlchemy                    1.4.32\n",
    "stack-data                    0.2.0\n",
    "statsmodels                   0.13.2\n",
    "sympy                         1.10.1\n",
    "tables                        3.6.1\n",
    "tabulate                      0.8.9\n",
    "tangled-up-in-unicode         0.2.0\n",
    "tbats                         1.1.3\n",
    "TBB                           0.2\n",
    "tblib                         1.7.0\n",
    "tenacity                      8.0.1\n",
    "tensorboard                   2.12.2\n",
    "tensorboard-data-server       0.7.0\n",
    "tensorboard-plugin-wit        1.8.1\n",
    "tensorflow-estimator          2.7.0\n",
    "tensorflow-gpu                2.7.4\n",
    "tensorflow-io-gcs-filesystem  0.31.0\n",
    "termcolor                     2.2.0\n",
    "terminado                     0.13.1\n",
    "testpath                      0.5.0\n",
    "text-unidecode                1.3\n",
    "textdistance                  4.2.1\n",
    "threadpoolctl                 2.2.0\n",
    "three-merge                   0.1.1\n",
    "tifffile                      2021.7.2\n",
    "tinycss                       0.4\n",
    "tldextract                    3.2.0\n",
    "tokenizers                    0.13.3\n",
    "toml                          0.10.2\n",
    "tomli                         1.2.2\n",
    "toolz                         0.11.2\n",
    "torch                         1.12.1\n",
    "tornado                       6.1\n",
    "tqdm                          4.64.0\n",
    "trace-updater                 0.0.9.1\n",
    "traitlets                     5.1.1\n",
    "transformers                  4.24.0\n",
    "triad                         0.8.6\n",
    "trio                          0.22.0\n",
    "Twisted                       22.2.0\n",
    "twisted-iocpsupport           1.0.2\n",
    "typed-ast                     1.4.3\n",
    "typing_extensions             4.5.0\n",
    "tzdata                        2023.3\n",
    "uc-micro-py                   1.0.1\n",
    "ujson                         5.1.0\n",
    "Unidecode                     1.2.0\n",
    "urllib3                       1.26.9\n",
    "virtualenv                    20.21.0\n",
    "visions                       0.7.5\n",
    "w3lib                         1.21.0\n",
    "watchdog                      2.1.6\n",
    "wcwidth                       0.2.5\n",
    "webencodings                  0.5.1\n",
    "websocket-client              0.58.0\n",
    "Werkzeug                      2.3.2\n",
    "wheel                         0.37.1\n",
    "widgetsnbextension            3.5.2\n",
    "win-inet-pton                 1.1.0\n",
    "win-unicode-console           0.5\n",
    "wincertstore                  0.2\n",
    "wrapt                         1.12.1\n",
    "wsproto                       1.2.0\n",
    "WTForms                       3.0.1\n",
    "xarray                        0.20.1\n",
    "xgboost                       1.7.5\n",
    "xlrd                          2.0.1\n",
    "XlsxWriter                    3.0.3\n",
    "xlwings                       0.24.9\n",
    "xxhash                        3.2.0\n",
    "yapf                          0.31.0\n",
    "yarl                          1.6.3\n",
    "yellowbrick                   1.5\n",
    "zict                          3.0.0\n",
    "zipp                          3.7.0\n",
    "zope.event                    4.6\n",
    "zope.interface                5.4.0\n",
    "zstandard                     0.19.0\n",
    "\n",
    "Python                        3.9.12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "api import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import glob\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from xgboost import XGBRegressor\n",
    "from typing import Tuple\n",
    "from haversine import haversine\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시드 제어 및 파일 저장을 위한 datetime import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Set random seed\n",
    "seed = 91345\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "import datetime\n",
    "date = datetime.datetime.now()\n",
    "date = date.strftime('%m%d_%H%M')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "작업량이 많은 관계로 gpu 제어를 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1 gpu 사용여부\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 경로 지정 및 bring 함수를 선언하여 파일을 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1.0 Done\n"
     ]
    }
   ],
   "source": [
    "# 1.0 train, test, answer data pathing & import\n",
    "path = './_data/finedust/'\n",
    "\n",
    "import glob\n",
    "train_pm_path = glob.glob(path + 'TRAIN/*.csv')\n",
    "test_pm_path = glob.glob(path + 'TEST_INPUT/*.csv')\n",
    "train_aws_path = glob.glob(path + 'TRAIN_AWS/*.csv')\n",
    "test_aws_path = glob.glob(path + 'TEST_AWS/*.csv')\n",
    "submission = pd.read_csv(path + 'answer_sample.csv', index_col=0)\n",
    "\n",
    "def bring(filepath:str)->pd.DataFrame:\n",
    "    li = []\n",
    "    for i in filepath:\n",
    "        df = pd.read_csv(i, index_col=None, header=0, encoding='utf-8-sig')\n",
    "        li.append(df)\n",
    "    data = pd.concat(li, axis=0, ignore_index=True)\n",
    "    return data\n",
    "\n",
    "train_pm = bring(train_pm_path)\n",
    "test_pm = bring(test_pm_path)\n",
    "train_aws = bring(train_aws_path)\n",
    "test_aws = bring(test_aws_path)\n",
    "\n",
    "print('# 1.0 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aws 데이터를 편리하게 이용하기 위한 LabelEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1.1 Done\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Local label encoding\n",
    "# 일 처리의 편의를 위해 label encoding을 한 것임 ( 나중에 이 값들은 drop 함 )\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label = LabelEncoder()\n",
    "\n",
    "train_pm['측정소'] = label.fit_transform(train_pm['측정소'])\n",
    "test_pm['측정소'] = label.transform(test_pm['측정소'])\n",
    "train_aws['지점'] = label.fit_transform(train_aws['지점'])\n",
    "test_aws['지점'] = label.transform(test_aws['지점'].ffill())\n",
    "\n",
    "print('# 1.1 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시간 열 생성 및 연도, 일시 열 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1.2 Done\n"
     ]
    }
   ],
   "source": [
    "# 1.2 Create hour columns (as period function) & remove year, date columns\n",
    "def get_hourly_features(hour: int):\n",
    "    \"\"\"주어진 시간(hour)에 대한 사인과 코사인 함수 값을 반환\"\"\"\n",
    "    radians_per_hour = 2 * np.pi * hour / 24.0\n",
    "    return [np.sin(radians_per_hour), np.cos(radians_per_hour)]\n",
    "\n",
    "train_pm['hour'] = train_pm['일시'].str[6:8].astype('int8')\n",
    "train_pm['hour_sin'], train_pm['hour_cos'] = get_hourly_features(train_pm['hour'])\n",
    "train_pm = train_pm.drop(['연도', '일시', 'hour'], axis=1)\n",
    "\n",
    "test_pm['hour'] = test_pm['일시'].str[6:8].astype('int8')\n",
    "test_pm['hour_sin'], test_pm['hour_cos'] = get_hourly_features(test_pm['hour'])\n",
    "test_pm = test_pm.drop(['연도', '일시', 'hour'], axis=1)\n",
    "\n",
    "train_aws = train_aws.drop(['연도', '일시'], axis=1)\n",
    "test_aws = test_aws.drop(['연도', '일시'], axis=1)\n",
    "\n",
    "print('# 1.2 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train 데이터의 결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1.3 Done\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Remove missing values of train_pm/aws   ( using imputer )\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "imputer = IterativeImputer(XGBRegressor())\n",
    "\n",
    "train_pm['PM2.5'] = imputer.fit_transform(train_pm['PM2.5'].values.reshape(-1 , 1)).reshape(-1,)\n",
    "\n",
    "train_aws['기온(°C)'] = imputer.fit_transform(train_aws['기온(°C)'].values.reshape(-1 , 1)).reshape(-1,)\n",
    "\n",
    "train_aws['풍향(deg)'] = imputer.fit_transform(train_aws['풍향(deg)'].values.reshape(-1 , 1)).reshape(-1,)\n",
    "\n",
    "train_aws['풍속(m/s)'] = imputer.fit_transform(train_aws['풍속(m/s)'].values.reshape(-1 , 1)).reshape(-1,)\n",
    "\n",
    "train_aws['강수량(mm)'] = imputer.fit_transform(train_aws['강수량(mm)'].values.reshape(-1 , 1)).reshape(-1,)\n",
    "\n",
    "train_aws['습도(%)'] = imputer.fit_transform(train_aws['습도(%)'].values.reshape(-1 , 1)).reshape(-1,)\n",
    "\n",
    "print('# 1.3 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "awsmap과 pmmap 데이터 경로 지정 및 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2.0 Done\n"
     ]
    }
   ],
   "source": [
    "# 2.0 awsmap, pmmap data pathing and import\n",
    "from typing import Tuple\n",
    "\n",
    "def load_aws_and_pm()->Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    path='./_data/finedust/'\n",
    "    path_list = os.listdir(path)\n",
    "\n",
    "    meta='/'.join([path, path_list[1]])\n",
    "    meta_list=os.listdir(meta)\n",
    "\n",
    "    awsmap = pd.read_csv('/'.join([meta,meta_list[0]]))\n",
    "    awsmap = awsmap.drop(awsmap.columns[-1], axis=1)\n",
    "    pmmap = pd.read_csv('/'.join([meta,meta_list[1]]))\n",
    "    pmmap = pmmap.drop(pmmap.columns[-1], axis=1)\n",
    "    return awsmap, pmmap\n",
    "\n",
    "awsmap, pmmap = load_aws_and_pm()\n",
    "\n",
    "print('# 2.0 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "awsmap과 pmmap 데이터 적용을 위한 지역 LabelEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2.1 Done\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Local label encoding for awsmap and pmmap\n",
    "awsmap['Location'] = label.fit_transform(awsmap['Location'])\n",
    "pmmap['Location'] = label.fit_transform(pmmap['Location'])\n",
    "\n",
    "print('# 2.1 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "awsmap과 pmmap의 지역명을 가나다 순으로 재정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2.2 Done\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Reorder awsmap, pmmap by area number (number encoding in alphabetical order)\n",
    "awsmap = awsmap.sort_values(by='Location')\n",
    "pmmap = pmmap.sort_values(by='Location')\n",
    "\n",
    "print('# 2.2 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pm관측소와 aws관측소 사이의 거리 출력\\\n",
    "haversine 설치 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2.3 Done\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Find the distance of the aws station from the pm station (17 x 30)\n",
    "from haversine import haversine\n",
    "\n",
    "def distance(awsmap:pd.DataFrame,pmmap:pd.DataFrame)->pd.DataFrame:\n",
    "    '''pm과 ams관측소 사이의 거리'''\n",
    "    a = []\n",
    "    for i in range(pmmap.shape[0]):\n",
    "        b=[]\n",
    "        for j in range(awsmap.shape[0]):\n",
    "            b.append(haversine((np.array(pmmap)[i, 1], np.array(pmmap)[i, 2]), (np.array(awsmap)[j, 1], np.array(awsmap)[j, 2])))\n",
    "        a.append(b)\n",
    "    distance = pd.DataFrame(np.array(a),index=pmmap['Location'],columns=awsmap['Location'])\n",
    "    return distance\n",
    "\n",
    "dist = distance(awsmap, pmmap)\n",
    "\n",
    "print('# 2.3 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pm관측소로부터 가장 가까운 n(=3)개의 aws관측소의 지역 번호 및 환산점수 반환(환산점수는 거리의 제곱에 반비례)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2.4 Done\n"
     ]
    }
   ],
   "source": [
    "# 2.4 Returns the index number and scaled weight of n (default=3) aws stations closest to the pm station\n",
    "def scaled_score(distance:pd.DataFrame,pmmap:pd.DataFrame,near:int=3)->Tuple[pd.DataFrame,np.ndarray]:\n",
    "    '''pm으로부터 가까운 상위 near개의 환산점수'''\n",
    "    min_i=[]\n",
    "    min_v=[]\n",
    "    for i in range(distance.shape[0]):\n",
    "        min_i.append(np.argsort(distance.values[i,:])[:near])\n",
    "        min_v.append(distance.values[i, min_i[i]])\n",
    "\n",
    "    min_i = np.array(min_i)\n",
    "    min_v = pd.DataFrame(np.array(min_v),index=distance.index)\n",
    "    \n",
    "    for i in range(pmmap.shape[0]):\n",
    "        for j in range(near):\n",
    "            min_v.values[i, j]=min_v.values[i, j]**2\n",
    "            \n",
    "    sum_min_v = np.sum(min_v, axis=1)\n",
    "\n",
    "    recip=[]\n",
    "    for i in range(pmmap.shape[0]):\n",
    "        recip.append(sum_min_v[i]/min_v.values[i, :])\n",
    "    recip = np.array(recip)\n",
    "    recip_sum = np.sum(recip, axis=1)\n",
    "    coef = 1/recip_sum\n",
    "\n",
    "    result = []\n",
    "    for i in range(pmmap.shape[0]):\n",
    "        result.append(recip[i, :]*coef[i])\n",
    "    result = pd.DataFrame(np.array(result),index=distance.index)\n",
    "    return result, min_i\n",
    "\n",
    "result, min_i = scaled_score(dist, pmmap)\n",
    "dist = dist.values\n",
    "result = result.values\n",
    "\n",
    "print('# 2.4 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "환산점수를 이용한 pm관측소의 날씨 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2.5 Done\n"
     ]
    }
   ],
   "source": [
    "# 2.5 Calculate the weather at the pm station\n",
    "train_pm = train_pm.values.reshape(17, -1, train_pm.shape[1])\n",
    "train_aws = train_aws.values.reshape(30, -1, train_aws.shape[1])\n",
    "test_pm = test_pm.values.reshape(17, -1, test_pm.shape[1])\n",
    "test_aws = test_aws.values.reshape(30, -1, test_aws.shape[1])\n",
    "\n",
    "train_pm_aws = []\n",
    "for i in range(17):\n",
    "    train_pm_aws.append(train_aws[min_i[i, 0], :, 1:]*result[0, 0] + train_aws[min_i[i, 1], :, 1:]*result[0, 1] + train_aws[min_i[i, 2], :, 1:]*result[0, 2])\n",
    "train_pm_aws = np.array(train_pm_aws)\n",
    "\n",
    "test_pm_aws = []\n",
    "for i in range(17):\n",
    "    test_pm_aws.append(test_aws[min_i[i, 0], :, 1:]*result[0, 0] + test_aws[min_i[i, 1], :, 1:]*result[0, 1] + test_aws[min_i[i, 2], :, 1:]*result[0, 2])\n",
    "\n",
    "test_pm_aws = np.array(test_pm_aws)\n",
    "\n",
    "print('# 2.5 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LabelEncoding된 지역 열 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2.6 Done\n"
     ]
    }
   ],
   "source": [
    "# 2.6 Local column drop\n",
    "train_pm = train_pm[:, :, 1:]\n",
    "test_pm = test_pm[:, :, 1:]\n",
    " \n",
    "print('# 2.6 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미세먼지 평균과 표준편차를 이용한 군집화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.7 Clustering into k regions with kMeans\n",
    "# 미세먼지 평균과 표준편차를 이용하여 k개의 군집으로 묶음 ( 일반지형, 해안인근지형, 분지지형에 따라 3개로 나눌 수 있다고 가정 )\n",
    "# 미세먼지 농도와 표준편차를 이용해 labeling한 값이므로 다른 지역을 추가하더라도 fit된 kmeans로 label 값만 부여해주면 globals 한 모델 적용가능\n",
    "# ex) 각 지역 train pm 데이터의 평균을\n",
    "# (-inf, 0.5]는 label 값 '0', (0.5, 0.75)는 label 값 '1', [0.75, inf)는 label 값 '2' 의 세 개의 군집으로 나누었다고 가정한다면,\n",
    "# 새로 추가하는 지역을 이 범위의 기준으로 label 값 부여\n",
    "from sklearn.cluster import KMeans\n",
    "import joblib\n",
    "\n",
    "pm_means = [np.mean(train_pm[i, :, 0]) for i in range(17)]\n",
    "pm_std = [np.std(train_pm[i, :, 0]) for i in range(17)]\n",
    "cluster = np.array(list(zip(pm_means, pm_std)))\n",
    "\n",
    "path_kmeans = './_save/w/'\n",
    "kmeans_weight:KMeans = joblib.load(path_kmeans + 'kmeans_joblib.joblib') \n",
    "\n",
    "\n",
    "k = 3\n",
    "\n",
    "model_kmeans = KMeans(n_clusters = k,\n",
    "                      init = kmeans_weight,\n",
    "                      max_iter = 300,\n",
    "                      n_init = 10,\n",
    "                      random_state = seed)\n",
    "model_kmeans.fit(cluster)\n",
    "\n",
    "labels = model_kmeans.labels_\n",
    "\n",
    "print('# 2.7 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMeans에 대한 One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2.8 Done\n"
     ]
    }
   ],
   "source": [
    "# 2.8 One-hot encoding of label value of kMeans\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "print('# 2.8 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련을 위한 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2.9 Done\n"
     ]
    }
   ],
   "source": [
    "# 2.9 Data Preparation\n",
    "train_pm_onehot = []\n",
    "for i in range(17):\n",
    "    for j in range(train_pm.shape[1]):\n",
    "        train_pm_onehot.append(np.concatenate([train_pm[i, j, :], labels[i, :]]))\n",
    "        \n",
    "train_pm_onehot = np.array(train_pm_onehot).reshape(17, -1, train_pm.shape[2]+k)\n",
    "train_data = np.concatenate([train_pm_onehot, train_pm_aws], axis=2)\n",
    "\n",
    "test_pm_onehot = []\n",
    "for i in range(17):\n",
    "    for j in range(test_pm.shape[1]):\n",
    "        test_pm_onehot.append(np.concatenate([test_pm[i, j, :], labels[i, :]]))\n",
    "\n",
    "test_pm_onehot = np.array(test_pm_onehot).reshape(17, -1, test_pm.shape[2]+k)\n",
    "pm_col_num = 0\n",
    "\n",
    "print('# 2.9 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x에 대한 분해 시계열 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 3.1 Done\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Split_x\n",
    "timesteps = 6\n",
    "\n",
    "def split_x(dt, ts, pred_date):\n",
    "    a = []\n",
    "    for j in range(dt.shape[0]):\n",
    "        b = []\n",
    "        for i in range(dt.shape[1]-ts-pred_date):\n",
    "            c = dt[j, i:i+ts, :]\n",
    "            b.append(c)\n",
    "        a.append(b)\n",
    "    return np.array(a)\n",
    "\n",
    "for i in range(72):\n",
    "    globals()[f'x{i+1}'] = split_x(train_data, timesteps, i).reshape(-1, timesteps, train_data.shape[2])\n",
    "\n",
    "print('# 3.1 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y에 대한 분해 시계열 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 3.2 Done\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Split_y\n",
    "for i in range(72):\n",
    "    globals()[f'y{i+1}'] = []\n",
    "    for j in range(train_data.shape[0]):\n",
    "        globals()[f'y{i+1}'].append(train_data[j, timesteps+i:, pm_col_num].reshape(-1,))\n",
    "    globals()[f'y{i+1}'] = np.array(globals()[f'y{i+1}']).reshape(-1,)\n",
    "\n",
    "print('# 3.2 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 3.3 Done\n"
     ]
    }
   ],
   "source": [
    "# 3.3 Train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for i in range(72):\n",
    "    globals()[f'x{i+1}_train'], globals()[f'x{i+1}_test'], globals()[f'y{i+1}_train'], globals()[f'y{i+1}_test'] = train_test_split(globals()[f'x{i+1}'], globals()[f'y{i+1}'], train_size=0.7, random_state=seed, shuffle=True)\n",
    "\n",
    "print('# 3.3 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 용량 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 3.4 Done\n"
     ]
    }
   ],
   "source": [
    "# 3.4 Reduce File Size ( float 64 -> float 32 )\n",
    "for i in range(72):\n",
    "    globals()[f'x{i+1}_train']=globals()[f'x{i+1}_train'].reshape(-1, timesteps, globals()[f'x{i+1}'].shape[2]).astype(np.float32)\n",
    "    globals()[f'x{i+1}_test']=globals()[f'x{i+1}_test'].reshape(-1, timesteps, globals()[f'x{i+1}'].shape[2]).astype(np.float32)\n",
    "    globals()[f'y{i+1}_train']=globals()[f'y{i+1}_train'].astype(np.float32)\n",
    "    globals()[f'y{i+1}_test']=globals()[f'y{i+1}_test'].astype(np.float32)\n",
    "\n",
    "print('# 3.4 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델, 컴파일, 훈련\\\n",
    "예측 해야하는 72시간에 대한 각 시간별 모델 72개 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 4.1 Done\n"
     ]
    }
   ],
   "source": [
    "# 4.1 Model, Compile, Fit\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    restore_best_weights=True,\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "rl = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    patience=2,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 모델을 load할땐 여기서 load\n",
    "\n",
    "for i in range(72):\n",
    "    globals()[f'model{i+1}'] = load_model(f\"./_save/w/0511_0920_91345_Submit{i+1}.h5\")\n",
    "\n",
    "print('# 4.1 Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test 데이터에 대한 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Predict\n",
    "l=[]\n",
    "for k in range(17):\n",
    "    for j in range(64):\n",
    "        for i in range(72):\n",
    "            test_pm[k, 120*j+i+48, pm_col_num] = globals()[f'model{i+1}'].predict\\\n",
    "                (np.concatenate([test_pm_onehot[k, 120*j+48-timesteps:120*j+48, :], test_pm_aws[k, 120*j+48-timesteps:120*j+48, :]], axis=1)\\\n",
    "                    .reshape(-1, timesteps, globals()['x{}_train'.format(i+1)].shape[2]).astype(np.float32))\n",
    "            print(f'model conversion state : {k} - {j} - {i}, {np.round((72*64*k+72*j+i+1)*100/(test_pm_onehot.shape[0]*test_pm_onehot.shape[1]*3//5), 3)}% complete')\n",
    "            # print(test_pm[k, 120*j+48:120*j+120, pm_col_num])\n",
    "        l.append(test_pm[k, 120*j+48:120*j+120, pm_col_num])\n",
    "\n",
    "print('# 5.1 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "후처리 과정 1\\\n",
    "pm 관측소의 관측 가능 최소 단위가 0.004로 여겨지므로, 이 단위를 기준으로 양자화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 5.2 Done\n"
     ]
    }
   ],
   "source": [
    "# 5.2 Post-processing 1\n",
    "l = np.array(l).reshape(-1,)\n",
    "\n",
    "quantization = 0.004\n",
    "l = np.round(l/quantization)*quantization\n",
    "l = l.reshape(17, -1)\n",
    "\n",
    "print('# 5.2 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "후처리 과정 2\\\n",
    "(모든 관측소에 대해 global 하게 적용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 5.3 Done\n"
     ]
    }
   ],
   "source": [
    "# 5.3 Post-processing 2\n",
    "# train data의 2일차까지를 train data로 만든 모델을 통해 predict한 결과값을\n",
    "# 예측 시간 단위로 시각화하여 대략적으로 보정\n",
    "# train data(3일차~5일차)의 실제값들의 평균(train_true)- train data(3일차~5일차)의 predict값들의 평균(train_predict)->plot\n",
    "\n",
    "primary_complement_point = 12\n",
    "secondary_complement_point = 56\n",
    "tertiary_complement_point = 68\n",
    "\n",
    "for j in range(17):\n",
    "    for i in range(64):\n",
    "        l[j, primary_complement_point+72*i:secondary_complement_point+72*i] = l[j, primary_complement_point+72*i:secondary_complement_point+72*i] - 1*quantization\n",
    "        l[j, secondary_complement_point+72*i:tertiary_complement_point+72*i] = l[j, secondary_complement_point+72*i:tertiary_complement_point+72*i] - 2*quantization\n",
    "        l[j, tertiary_complement_point+72*i:72+72*i] = l[j, tertiary_complement_point+72*i:72+72*i] - 3*quantization\n",
    "\n",
    "print('# 5.3 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제출 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 5.4 Done\n"
     ]
    }
   ],
   "source": [
    "# 5.4 Save Submit\n",
    "l = l.reshape(-1,)\n",
    "submission['PM2.5']=l\n",
    "\n",
    "path_save = './_save/predict/'\n",
    "submission.to_csv(path_save + f'아둔토리다스{seed}' + date + '.csv')\n",
    "\n",
    "print('# 5.4 Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5.5 Save weigths\n",
    "# for i in range(72):\n",
    "#     globals()[f'model{i+1}'].save(f'./_save/w2/Aiur_Submit{i+1}.h5')\n",
    "\n",
    "# print('# 5.5 Done')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
